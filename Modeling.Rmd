---
title: "Scoring"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Library pour modélisation
```{r}
library(xgboost)
library(plotROC)
library(glmnet)
library(randomForest)
library(data.table)
```

Création d'une variable année pour faire notre cross validation
On retire toutes les variables quali
```{r}
load("Data/table_score.RData")
table_score_sauv<-table_score
#Création de l'annee
Annee<-substr(as.character(table_score$tourney_date),1,4)
#Dernier retraitement 

table_score<-cbind(table_score,Annee)
table_score<-na.omit(table_score)
f_replaceNA = function(DT) {
  
  for (j in seq_len(ncol(DT)))
    
    set(DT,which(is.na(DT[[j]])),j,0)
  
}

f_replaceNA(table_score)
table_score[,cible:=as.factor(coin)]
training_table <- table_score[Annee<2018,]
test_table <- table_score[Annee==2018,]

training_table[,c("tourney_id","tourney_name","surface","tourney_date","tourney_level","match_num","round","round_num","p1_id","p1_name","p2_id","p2_name") := NULL]
test_table[,c("tourney_id","tourney_name","surface","tourney_date","tourney_level","match_num","round","round_num","p1_id","p1_name","p2_id","p2_name") := NULL]

```
Paramètres de la boucle AnneeDeb est la première année sur laquelle 
on veut faire de la prédiction de l AnneeDeb à l AnneeFin, en regardant 4
ans dans le passé.
Le paramètre RES est à regler en fonction des modèles appliqués
## Including Plots

Preparation des paramètres ante-modèlisation (RES est à modifier selon les modèles utilisés)
```{r}

RES<- data.frame(Y=test_table$coin,RegLog=0,Ridge1=0,Ridge2=0,ElNet=0,
                 SVM=0,Reseau=0,XGBoost=0,SVM2=0,Reseau2=0)
set.seed(1234)


```

Modélisation en boucle
train <- data.frame(churn_x, churn_y)

model_glmnet <- train(churn_y ~ ., data = train,
  metric = "ROC",
  method = "glmnet",
  trControl = myControl
)
<<<<<<< HEAD

Modélisation boucle for
```{r}
load("Data/table_score.RData")
table_score<-na.omit(table_score)
f_replaceNA = function(DT) {
  
  for (j in seq_len(ncol(DT)))
    
    set(DT,which(is.na(DT[[j]])),j,0)
  
}
func<- function(x){
  ifelse(x<0.50,0,1)
}

f_replaceNA(table_score)
table_score[,cible:=as.factor(coin)]

ech<-sample(1:nrow(table_score))
cbind(table_score,ech)
bloc<-4
nbr_ligne<-1000
table_score_new <- table_score[ech<nbr_ligne,]
indb <- sample(1:nrow(table_score_new)%%bloc+1)

RES<-data.frame(Y=table_score_new$cible,RegLog=0,Ridge=0,ElNet=0,                  Lasso=0, SVM=0,Reseau=0,XGBoost=0,SVM2=0,Reseau2=0)

ntree<-100

for (i in 1:bloc){
  table_score_new <- table_score[ech<nbr_ligne,][,c("tourney_id","tourney_name","surface","tourney_date","tourney_level","match_num","round","round_num","p1_id","p1_name","p2_id","p2_name") := NULL]
Ytrain <- as.matrix(table_score_new[,c("cible")])[indb!=i,]
Xtrain <- as.matrix(table_score_new[,c("coin","cible"):=NULL])[indb!=i,]
Xtest<-as.matrix(table_score_new[indb==i,])
  mod1 <- glmnet(Xtrain,Ytrain, family='binomial',standardize = TRUE,lambda=0, alpha=0) # <------------ Reg log
 RES[indb==i,"RegLog"]<- predict(mod1,Xtest, type='class', s=c(0)) 
#sum(test_table$coin == pred1)/nrow(test_table)

#2) Ridge
mod2 <- glmnet(Xtrain,Ytrain,family='binomial',alpha=0)

cv_mod2 <- cv.glmnet(Xtrain,Ytrain,family='binomial',type.measure='class',nfolds=10,alpha=0,keep=TRUE)

pred2 <- predict(cv_mod2,Xtest,s=c(cv_mod2$lambda.min,cv_mod2$lambda.1se),type='class')
RES[indb==i,"Ridge"]  <- pred2[,2]



#3) Elasticnet
mod3 <- glmnet(Xtrain,Ytrain,family='binomial', alpha=0.5)
cv_mod3 <- cv.glmnet(Xtrain,Ytrain,family='binomial',type.measure='class',nfolds=10,alpha=0.5,foldid=cv_mod2$foldid) 
RES[indb==i,"ElNet"] <- predict(cv_mod3,Xtest,type='class',s=c(cv_mod3$lambda.min))

#4)Lasso
mod4 <- glmnet(Xtrain,Ytrain,family='binomial',alpha=1)
cv_mod4 <- cv.glmnet(Xtrain,Ytrain,family='binomial',type.measure='class',nfolds=10,alpha=1,keep=TRUE)
RES[indb==i,"Lasso"]  <- predict(cv_mod4,Xtest,type='class',s=c(cv_mod4$lambda.min))

#5)XGBoost
 xgboost_csv<- xgb.cv(data=Xtrain, label = Ytrain, max.depth=15,nfold=5, eta=2/ntree, nrounds=ntree,objective="binary:logistic")
 
 xgboost_csv<- xgb.cv(data=Xtrain,label = Ytrain, max.depth=15,nfold=5, eta=2/ntree, nrounds=ntree,objective="binary:logistic")
  y_pred<-predict(xgboost_mod,Xtest)
  RES[indb==i,"XGBoost"] <-lapply(y_pred,FUN = func)

}
  Err<-function(x){
   err<- 1-sum(RES[x]==RES["Y"])/nrow(RES)
   return(err)
  }
err_Xgb<-Err("XGBoost")
err_Elnet<-Err("ElNet")
err_Lasso<-Err("Lasso")
err_Ridge<-Err("Ridge")
err_Reglog<-Err("RegLog")
err_Xgb
err_Elnet
err_Lasso
err_Ridge
err_Reglog

xgboostModelCV <- xgb.cv(data =  DMMatrixTrain, nrounds = ntrees, nfold = 5, showsd = TRUE, 
                           metrics = "rmse", verbose = TRUE, "eval_metric" = "rmse",
                           "objective" = "reg:linear", "max.depth" = 15, "eta" = 2/ntrees,                               
                           "subsample" = currentSubsampleRate, "colsample_bytree" = currentColsampleRate)
```

```{r}

load("Data/table_score.RData")
table_score<-na.omit(table_score)
f_replaceNA = function(DT) {
  
  for (j in seq_len(ncol(DT)))
    
    set(DT,which(is.na(DT[[j]])),j,0)
  
}
func<- function(x){
  ifelse(x<0.50,0,1)
}

f_replaceNA(table_score)
table_score[,cible:=as.factor(coin)]

ech<-sample(1:nrow(table_score))
cbind(table_score,ech)
bloc<-4
nbr_ligne<-1000
table_score_new <- table_score[ech<nbr_ligne,]
indb <- sample(1:nrow(table_score_new)%%bloc+1)

RES<-data.frame(Y=table_score_new$cible,RegLog=0,Ridge=0,ElNet=0,                  Lasso=0, SVM=0,Reseau=0,XGBoost=0,SVM2=0,Reseau2=0)
for (i in 1:bloc){
i=1
  table_score_new <- table_score[ech<nbr_ligne,][,c("tourney_id","tourney_name","surface","tourney_date","tourney_level","match_num","round","round_num","p1_id","p1_name","p2_id","p2_name") := NULL]
Ytrain <- as.matrix(table_score_new[,c("cible")])[indb!=i,]
Xtrain <- as.matrix(table_score_new[,c("coin","cible"):=NULL])[indb!=i,]
Xtest<-as.matrix(table_score_new[indb==i,])
  mod1 <- glmnet(Xtrain,Ytrain, family='binomial',standardize = TRUE,lambda=0, alpha=0) # <------------ Reg log
 RES[indb==i,"RegLog"]<- predict(mod1,Xtest, type='class', s=c(0)) 
#sum(test_table$coin == pred1)/nrow(test_table)

#2) Ridge
mod2 <- glmnet(Xtrain,Ytrain,family='binomial',alpha=0)

cv_mod2 <- cv.glmnet(Xtrain,Ytrain,family='binomial',type.measure='class',nfolds=10,alpha=0,keep=TRUE)

pred2 <- predict(cv_mod2,Xtest,s=c(cv_mod2$lambda.min,cv_mod2$lambda.1se),type='class')
RES[indb==i,"Ridge"]  <- pred2[,2]



#3) Elasticnet
mod3 <- glmnet(Xtrain,Ytrain,family='binomial', alpha=0.5)
cv_mod3 <- cv.glmnet(Xtrain,Ytrain,family='binomial',type.measure='class',nfolds=10,alpha=0.5,foldid=cv_mod2$foldid) 
RES[indb==i,"ElNet"] <- predict(cv_mod3,Xtest,type='class',s=c(cv_mod3$lambda.min))

#4)Lasso
mod4 <- glmnet(Xtrain,Ytrain,family='binomial',alpha=1)
cv_mod4 <- cv.glmnet(Xtrain,Ytrain,family='binomial',type.measure='class',nfolds=10,alpha=1,keep=TRUE)
RES[indb==i,"Lasso"]  <- predict(cv_mod4,Xtest,type='class',s=c(cv_mod4$lambda.min))

 xgboost_mod<- xgboost(data=Xtrain,label = Ytrain, max.depth=25, eta=0.1, nrounds=32,objective="binary:logistic")
  y_pred<-predict(xgboost_mod,Xtest)
  RES[indb==i,"XGBoost"] <-lapply(y_pred,FUN = func)

}
  Err<-function(x){
   err<- 1-sum(RES[x]==RES["Y"])/nrow(RES)
   return(err)
  }
err_Xgb<-Err("XGBoost")
err_Elnet<-Err("ElNet")
err_Lasso<-Err("Lasso")
err_Ridge<-Err("Ridge")
err_Reglog<-Err("RegLog")
err_Xgb
err_Elnet
err_Lasso
err_Ridge
err_Reglog
```

```{r}
param <- list(objective = "binary:logistic",
      max_depth = 8,
      eta = 0.05,
      gamma = 0.01, 
      subsample = 0.9,
      colsample_bytree = 0.8, 
      min_child_weight = 4,
      max_delta_step = 1
      )
cv.nround = 1000
cv.nfold = 5
mdcv <- xgb.cv(data=Xtrain,labels=Ytrain, params = param, nthread=6, 
                nfold=cv.nfold, nrounds=cv.nround,
                verbose = T)
```

